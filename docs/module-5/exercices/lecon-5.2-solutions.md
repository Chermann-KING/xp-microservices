# Exercices - Le√ßon 5.2 Communication Asynchrone avec Message Queues

## Exercice 1 : Expansion RabbitMQ Producer/Consumer

### √ânonc√©

**Objectif** : Enrichir le flux de messaging avec des donn√©es suppl√©mentaires.

**T√¢ches** :

1. Modifier le **Booking Management Microservice** (producer) pour inclure dans le payload :

   - Email de l'utilisateur
   - Num√©ro de t√©l√©phone
   - Prix total
   - Nom du tour

2. Mettre √† jour le **Notification Microservice** (consumer) pour :

   - Extraire ces informations suppl√©mentaires
   - Afficher un message de notification r√©aliste : `"Email envoy√© √† user@example.com pour le tour 'Paris City Tour' d'un montant de 199.99 USD"`

3. **Bonus** : Exp√©rimenter avec diff√©rentes routing keys :
   - `booking.confirmed.premium`
   - `booking.confirmed.standard`
   - Modifier le consumer pour s'abonner √† tous les √©v√©nements de r√©servation : `booking.confirmed.*`

---

### Solution

#### Partie 1 : Producer Enrichi (Booking Service)

```javascript
// booking-management-service/src/rabbitmqProducer.js
const amqp = require("amqplib");

const RABBITMQ_URL =
  process.env.RABBITMQ_URL || "amqp://guest:guest@localhost:5672";
const EXCHANGE_NAME = "tour_booking_events";

let channel;

/**
 * Connexion √† RabbitMQ et cr√©ation de l'exchange
 */
async function connectRabbitMQ() {
  try {
    const connection = await amqp.connect(RABBITMQ_URL);
    channel = await connection.createChannel();

    // Cr√©er un exchange de type "topic" durable
    await channel.assertExchange(EXCHANGE_NAME, "topic", { durable: true });

    console.log("‚úÖ Connect√© √† RabbitMQ");
  } catch (error) {
    console.error("‚ùå √âchec de connexion √† RabbitMQ:", error);
    process.exit(1);
  }
}

/**
 * Publier un √©v√©nement "Tour R√©serv√©" avec donn√©es enrichies
 * @param {Object} bookingDetails - D√©tails complets de la r√©servation
 * @returns {boolean} - Succ√®s de la publication
 */
async function publishTourBookedEvent(bookingDetails) {
  if (!channel) {
    console.error("‚ùå Canal RabbitMQ non √©tabli.");
    return false;
  }

  // D√©terminer la routing key selon le type de tour
  const tourType = bookingDetails.tourType || "standard"; // 'premium' ou 'standard'
  const routingKey = `booking.confirmed.${tourType}`;

  // Payload enrichi avec toutes les informations n√©cessaires
  const enrichedPayload = {
    bookingId: bookingDetails.bookingId,
    tourId: bookingDetails.tourId,
    tourName: bookingDetails.tourName,
    tourType: tourType,
    userId: bookingDetails.userId,
    userEmail: bookingDetails.userEmail,
    userPhone: bookingDetails.userPhone,
    userName: bookingDetails.userName,
    bookingDate: bookingDetails.bookingDate,
    tourDate: bookingDetails.tourDate,
    participants: bookingDetails.participants,
    totalPrice: bookingDetails.totalPrice,
    currency: bookingDetails.currency || "USD",
    status: "confirmed",
    timestamp: new Date().toISOString(),
  };

  const message = JSON.stringify(enrichedPayload);

  try {
    // Publier le message vers l'exchange avec la routing key
    channel.publish(EXCHANGE_NAME, routingKey, Buffer.from(message), {
      persistent: true, // Message persistant
      contentType: "application/json",
      timestamp: Date.now(),
    });

    console.log(`üì® Message publi√© '${routingKey}': ${message}`);
    return true;
  } catch (error) {
    console.error("‚ùå √âchec de publication du message:", error);
    return false;
  }
}

module.exports = {
  connectRabbitMQ,
  publishTourBookedEvent,
};
```

#### Partie 2 : Route de R√©servation Enrichie

```javascript
// booking-management-service/src/routes/bookingRoutes.js
const express = require("express");
const router = express.Router();
const { bookTour } = require("../controllers/bookingController");
const { publishTourBookedEvent } = require("../rabbitmqProducer");
const { getTourById } = require("../services/tourService");
const { getUserById } = require("../services/userService");

router.post("/bookings", async (req, res) => {
  try {
    const bookingData = req.body;

    // 1. Cr√©er la r√©servation en base de donn√©es
    const newBooking = await bookTour(bookingData);

    // 2. R√©cup√©rer les d√©tails du tour et de l'utilisateur
    const tour = await getTourById(newBooking.tourId);
    const user = await getUserById(newBooking.userId);

    // 3. Publier l'√©v√©nement avec toutes les donn√©es enrichies
    const eventPublished = await publishTourBookedEvent({
      bookingId: newBooking.id,
      tourId: newBooking.tourId,
      tourName: tour.name,
      tourType: tour.type, // 'premium' ou 'standard'
      userId: newBooking.userId,
      userEmail: user.email,
      userPhone: user.phone,
      userName: user.name,
      bookingDate: newBooking.createdAt,
      tourDate: newBooking.tourDate,
      participants: newBooking.participants,
      totalPrice: newBooking.totalPrice,
      currency: "USD",
    });

    if (!eventPublished) {
      console.warn("‚ö†Ô∏è √âchec de publication de l'√©v√©nement vers RabbitMQ.");
    }

    res.status(201).json({
      message: "R√©servation r√©ussie",
      booking: newBooking,
    });
  } catch (error) {
    console.error("‚ùå Erreur lors de la r√©servation:", error);
    res.status(500).json({
      message: "Erreur lors de la r√©servation",
      error: error.message,
    });
  }
});

module.exports = router;
```

#### Partie 3 : Consumer Enrichi (Notification Service)

```javascript
// notification-service/src/rabbitmqConsumer.js
const amqp = require("amqplib");

const RABBITMQ_URL =
  process.env.RABBITMQ_URL || "amqp://guest:guest@localhost:5672";
const EXCHANGE_NAME = "tour_booking_events";
const QUEUE_NAME = "notification_queue";

// Pattern pour s'abonner √† tous les √©v√©nements de r√©servation
const ROUTING_KEY_PATTERN = "booking.confirmed.*"; // Wildcard pour premium ET standard

/**
 * Formater le message de notification
 */
function formatNotificationMessage(eventData) {
  const {
    userName,
    userEmail,
    tourName,
    tourType,
    totalPrice,
    currency,
    participants,
    tourDate,
    bookingId,
  } = eventData;

  const typeLabel = tourType === "premium" ? "‚≠ê Premium" : "Standard";

  return `
üìß Email envoy√© √† ${userEmail} pour le tour "${tourName}" (${typeLabel})
   üë§ Client: ${userName}
   üí∞ Montant: ${totalPrice} ${currency}
   üë• Participants: ${participants} personne(s)
   üìÖ Date du tour: ${new Date(tourDate).toLocaleDateString("fr-FR")}
   üÜî ID R√©servation: ${bookingId}
    `.trim();
}

/**
 * Envoyer une notification par email (simulation)
 */
async function sendEmailNotification(eventData) {
  // Dans un vrai syst√®me, utiliser un service comme SendGrid, Mailgun, etc.
  console.log("\nüì¨ Envoi d'email de confirmation...");
  console.log(formatNotificationMessage(eventData));
  console.log("‚úÖ Email envoy√© avec succ√®s!\n");

  // Simulation d'un d√©lai d'envoi
  await new Promise((resolve) => setTimeout(resolve, 500));
}

/**
 * Envoyer une notification par SMS (simulation)
 */
async function sendSmsNotification(eventData) {
  const { userPhone, tourName, tourDate } = eventData;

  console.log("\nüì± Envoi de SMS...");
  console.log(`   Destinataire: ${userPhone}`);
  console.log(
    `   Message: Votre r√©servation pour "${tourName}" le ${new Date(
      tourDate
    ).toLocaleDateString("fr-FR")} est confirm√©e!`
  );
  console.log("‚úÖ SMS envoy√© avec succ√®s!\n");

  await new Promise((resolve) => setTimeout(resolve, 300));
}

/**
 * D√©marrer la consommation de messages
 */
async function startConsuming() {
  try {
    const connection = await amqp.connect(RABBITMQ_URL);
    const channel = await connection.createChannel();

    // Assurer que l'exchange existe
    await channel.assertExchange(EXCHANGE_NAME, "topic", { durable: true });

    // Cr√©er une queue durable
    const q = await channel.assertQueue(QUEUE_NAME, { durable: true });

    // Lier la queue √† l'exchange avec le pattern wildcard
    await channel.bindQueue(q.queue, EXCHANGE_NAME, ROUTING_KEY_PATTERN);

    console.log(`üì¨ En attente de messages dans ${q.queue}`);
    console.log(`   Pattern de routing: ${ROUTING_KEY_PATTERN}`);
    console.log("   CTRL+C pour quitter\n");

    // Consommer les messages
    channel.consume(
      q.queue,
      async (msg) => {
        if (msg.content) {
          const eventData = JSON.parse(msg.content.toString());
          const routingKey = msg.fields.routingKey;

          console.log(`\nüì® √âv√©nement re√ßu: '${routingKey}'`);

          try {
            // D√©terminer le type de notification selon la routing key
            if (routingKey === "booking.confirmed.premium") {
              console.log(
                "üåü R√©servation Premium d√©tect√©e - Envoi notifications prioritaires"
              );
              // Pour les premium, envoyer email ET SMS
              await sendEmailNotification(eventData);
              await sendSmsNotification(eventData);
            } else if (routingKey === "booking.confirmed.standard") {
              console.log("üìß R√©servation Standard d√©tect√©e - Envoi email");
              // Pour les standard, envoyer uniquement email
              await sendEmailNotification(eventData);
            }

            // Accuser r√©ception du message (tr√®s important!)
            channel.ack(msg);
          } catch (error) {
            console.error("‚ùå Erreur lors du traitement du message:", error);
            // Rejeter le message et le remettre dans la queue
            channel.nack(msg, false, true);
          }
        }
      },
      {
        noAck: false, // Accus√© de r√©ception manuel
      }
    );
  } catch (error) {
    console.error("‚ùå √âchec de d√©marrage du consumer RabbitMQ:", error);
    process.exit(1);
  }
}

// D√©marrer la consommation au d√©marrage du service
startConsuming();
```

#### Partie 4 : Services Mock (pour les donn√©es enrichies)

```javascript
// booking-management-service/src/services/tourService.js

/**
 * R√©cup√©rer les d√©tails d'un tour par ID
 * (Dans un vrai syst√®me, ceci ferait un appel √† la base de donn√©es)
 */
async function getTourById(tourId) {
  // Simulation de donn√©es
  const tours = {
    tour_001: {
      id: "tour_001",
      name: "Paris City Tour",
      type: "standard",
      duration: "3 heures",
      price: 199.99,
    },
    tour_002: {
      id: "tour_002",
      name: "Tour Eiffel Experience Premium",
      type: "premium",
      duration: "5 heures",
      price: 499.99,
    },
    tour_003: {
      id: "tour_003",
      name: "Versailles Palace Tour",
      type: "standard",
      duration: "6 heures",
      price: 299.99,
    },
  };

  return (
    tours[tourId] || {
      id: tourId,
      name: "Tour Inconnu",
      type: "standard",
      price: 0,
    }
  );
}

module.exports = { getTourById };
```

```javascript
// booking-management-service/src/services/userService.js

/**
 * R√©cup√©rer les d√©tails d'un utilisateur par ID
 * (Dans un vrai syst√®me, ceci ferait un appel √† la base de donn√©es)
 */
async function getUserById(userId) {
  // Simulation de donn√©es
  const users = {
    user_001: {
      id: "user_001",
      name: "Tony Stark",
      email: "tony.stark@avengers.com",
      phone: "+1-555-0100",
    },
    user_002: {
      id: "user_002",
      name: "Bruce Wayne",
      email: "bruce.wayne@wayne.com",
      phone: "+1-555-0200",
    },
    user_003: {
      id: "user_003",
      name: "Peter Parker",
      email: "peter.parker@dailybugle.com",
      phone: "+1-555-0300",
    },
  };

  return (
    users[userId] || {
      id: userId,
      name: "Utilisateur Inconnu",
      email: "unknown@example.com",
      phone: "+0-000-0000",
    }
  );
}

module.exports = { getUserById };
```

#### R√©sultat Attendu

Quand une r√©servation premium est cr√©√©e :

```
üì® Message publi√© 'booking.confirmed.premium': {"bookingId":"bkg_123",...}

üì® √âv√©nement re√ßu: 'booking.confirmed.premium'
üåü R√©servation Premium d√©tect√©e - Envoi notifications prioritaires

üì¨ Envoi d'email de confirmation...
üìß Email envoy√© √† tony.stark@avengers.com pour le tour "Tour Eiffel Experience Premium" (‚≠ê Premium)
   üë§ Client: Tony Stark
   üí∞ Montant: 499.99 USD
   üë• Participants: 2 personne(s)
   üìÖ Date du tour: 15/02/2024
   üÜî ID R√©servation: bkg_123
‚úÖ Email envoy√© avec succ√®s!

üì± Envoi de SMS...
   Destinataire: +1-555-0100
   Message: Votre r√©servation pour "Tour Eiffel Experience Premium" le 15/02/2024 est confirm√©e!
‚úÖ SMS envoy√© avec succ√®s!
```

---

## Exercice 2 : Am√©lioration Kafka Producer/Consumer

### √ânonc√©

**Objectif** : Impl√©menter la gestion d'erreurs et l'idempotence.

**T√¢ches** :

1. **Gestion d'erreurs pour le producer** :

   - Impl√©menter un m√©canisme de retry avec backoff exponentiel en cas d'√©chec d'envoi
   - Logger les √©checs persistants

2. **Idempotence du consumer** :

   - Ajouter un syst√®me de v√©rification pour √©viter de traiter deux fois le m√™me message
   - Utiliser Redis pour stocker les `bookingId` d√©j√† trait√©s

3. **Correlation ID** :
   - Ajouter un `correlationId` dans les headers du message
   - Propager ce `correlationId` dans tous les logs pour le tracing end-to-end

---

### Solution

#### Partie 1 : Kafka Producer avec Retry et Correlation ID

```javascript
// booking-management-service/src/kafkaProducer.js
const { Kafka, logLevel } = require("kafkajs");
const { v4: uuidv4 } = require("uuid");

const KAFKA_BROKERS = [process.env.KAFKA_BROKER || "localhost:9092"];
const TOPIC_NAME = "tour_booking_events";

const kafka = new Kafka({
  clientId: "booking-management-service",
  brokers: KAFKA_BROKERS,
  logLevel: logLevel.ERROR,
  retry: {
    initialRetryTime: 100,
    retries: 8,
  },
});

const producer = kafka.producer({
  idempotent: true, // Garantit que les messages ne sont pas dupliqu√©s
  maxInFlightRequests: 5,
  transactionalId: "booking-producer-tx-id",
});

/**
 * Connexion du producer Kafka
 */
async function connectKafkaProducer() {
  try {
    await producer.connect();
    console.log("‚úÖ Kafka Producer connect√©");
  } catch (error) {
    console.error("‚ùå √âchec de connexion Kafka Producer:", error);
    process.exit(1);
  }
}

/**
 * Retry avec backoff exponentiel
 * @param {Function} fn - Fonction √† r√©essayer
 * @param {number} maxRetries - Nombre maximum de tentatives
 * @param {string} correlationId - ID de corr√©lation pour les logs
 */
async function retryWithBackoff(fn, maxRetries = 5, correlationId) {
  let lastError;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;

      if (attempt === maxRetries) {
        console.error(
          `‚ùå [${correlationId}] √âchec d√©finitif apr√®s ${maxRetries} tentatives:`,
          error.message
        );
        throw error;
      }

      // Backoff exponentiel: 2^attempt * 100ms
      const delayMs = Math.pow(2, attempt) * 100;
      console.warn(
        `‚ö†Ô∏è [${correlationId}] Tentative ${attempt}/${maxRetries} √©chou√©e. Nouvelle tentative dans ${delayMs}ms...`
      );

      await new Promise((resolve) => setTimeout(resolve, delayMs));
    }
  }

  throw lastError;
}

/**
 * Publier un √©v√©nement "Tour R√©serv√©" vers Kafka avec retry et correlation ID
 * @param {Object} bookingDetails - D√©tails de la r√©servation
 * @param {string} correlationId - ID de corr√©lation (optionnel, g√©n√©r√© si absent)
 * @returns {Object} - { success: boolean, correlationId: string }
 */
async function publishTourBookedEventKafka(
  bookingDetails,
  correlationId = null
) {
  // G√©n√©rer un correlation ID si non fourni
  const corrId = correlationId || uuidv4();

  if (!producer) {
    console.error(`‚ùå [${corrId}] Kafka producer non initialis√©.`);
    return { success: false, correlationId: corrId };
  }

  const message = JSON.stringify(bookingDetails);

  try {
    console.log(`üì§ [${corrId}] Tentative d'envoi du message vers Kafka...`);

    // Utiliser retry avec backoff exponentiel
    await retryWithBackoff(
      async () => {
        await producer.send({
          topic: TOPIC_NAME,
          messages: [
            {
              key: bookingDetails.bookingId.toString(),
              value: message,
              headers: {
                eventType: "booking.confirmed",
                correlationId: corrId,
                timestamp: Date.now().toString(),
                source: "booking-management-service",
                version: "1.0",
              },
            },
          ],
        });
      },
      5,
      corrId
    );

    console.log(`‚úÖ [${corrId}] Message publi√© vers Kafka avec succ√®s`);
    return { success: true, correlationId: corrId };
  } catch (error) {
    console.error(
      `‚ùå [${corrId}] √âchec d√©finitif de publication Kafka:`,
      error
    );

    // Logger l'√©chec dans un syst√®me de monitoring (ex: Sentry, DataDog)
    // await logToMonitoring('kafka_publish_failure', { corrId, error, bookingDetails });

    return { success: false, correlationId: corrId, error: error.message };
  }
}

/**
 * D√©connexion gracieuse
 */
async function disconnectKafkaProducer() {
  try {
    await producer.disconnect();
    console.log("Kafka Producer d√©connect√©");
  } catch (error) {
    console.error("Erreur lors de la d√©connexion:", error);
  }
}

// Gestion de l'arr√™t gracieux
process.on("SIGTERM", disconnectKafkaProducer);
process.on("SIGINT", disconnectKafkaProducer);

module.exports = {
  connectKafkaProducer,
  publishTourBookedEventKafka,
  disconnectKafkaProducer,
};
```

#### Partie 2 : Kafka Consumer avec Idempotence (Redis)

```javascript
// notification-service/src/kafkaConsumer.js
const { Kafka, logLevel } = require("kafkajs");
const redis = require("redis");
const { promisify } = require("util");

const KAFKA_BROKERS = [process.env.KAFKA_BROKER || "localhost:9092"];
const TOPIC_NAME = "tour_booking_events";
const GROUP_ID = "notification_service_group";

// Configuration Redis pour l'idempotence
const redisClient = redis.createClient({
  host: process.env.REDIS_HOST || "localhost",
  port: process.env.REDIS_PORT || 6379,
  retry_strategy: (options) => {
    if (options.total_retry_time > 1000 * 60 * 60) {
      return new Error("Redis retry time exhausted");
    }
    return Math.min(options.attempt * 100, 3000);
  },
});

const getAsync = promisify(redisClient.get).bind(redisClient);
const setexAsync = promisify(redisClient.setex).bind(redisClient);

const kafka = new Kafka({
  clientId: "notification-service",
  brokers: KAFKA_BROKERS,
  logLevel: logLevel.ERROR,
});

const consumer = kafka.consumer({
  groupId: GROUP_ID,
  sessionTimeout: 30000,
  heartbeatInterval: 3000,
});

/**
 * V√©rifier si un message a d√©j√† √©t√© trait√© (idempotence)
 * @param {string} bookingId - ID de la r√©servation
 * @param {string} correlationId - ID de corr√©lation pour les logs
 * @returns {boolean} - true si d√©j√† trait√©
 */
async function isMessageAlreadyProcessed(bookingId, correlationId) {
  try {
    const key = `processed:booking:${bookingId}`;
    const result = await getAsync(key);

    if (result) {
      console.log(`‚ö†Ô∏è [${correlationId}] Message d√©j√† trait√©: ${bookingId}`);
      return true;
    }

    return false;
  } catch (error) {
    console.error(
      `‚ùå [${correlationId}] Erreur Redis lors de la v√©rification:`,
      error
    );
    // En cas d'erreur Redis, on continue pour ne pas bloquer le traitement
    return false;
  }
}

/**
 * Marquer un message comme trait√©
 * @param {string} bookingId - ID de la r√©servation
 * @param {string} correlationId - ID de corr√©lation
 * @param {number} ttlSeconds - Dur√©e de vie en secondes (par d√©faut 24h)
 */
async function markMessageAsProcessed(
  bookingId,
  correlationId,
  ttlSeconds = 86400
) {
  try {
    const key = `processed:booking:${bookingId}`;
    const value = JSON.stringify({
      processedAt: new Date().toISOString(),
      correlationId: correlationId,
    });

    await setexAsync(key, ttlSeconds, value);
    console.log(
      `‚úÖ [${correlationId}] Message marqu√© comme trait√©: ${bookingId} (expire dans ${ttlSeconds}s)`
    );
  } catch (error) {
    console.error(
      `‚ùå [${correlationId}] Erreur Redis lors du marquage:`,
      error
    );
  }
}

/**
 * Traiter un message de r√©servation
 * @param {Object} eventData - Donn√©es de l'√©v√©nement
 * @param {string} correlationId - ID de corr√©lation
 */
async function processBookingEvent(eventData, correlationId) {
  const { bookingId, userId, tourName, totalPrice } = eventData;

  console.log(`\nüìß [${correlationId}] Traitement de la notification...`);
  console.log(`   R√©servation: ${bookingId}`);
  console.log(`   Utilisateur: ${userId}`);
  console.log(`   Tour: ${tourName}`);
  console.log(`   Montant: ${totalPrice} USD`);

  // Simuler l'envoi d'email (dans un vrai syst√®me, utiliser SendGrid, etc.)
  await new Promise((resolve) => setTimeout(resolve, 1000));

  console.log(`‚úÖ [${correlationId}] Notification envoy√©e avec succ√®s!\n`);
}

/**
 * D√©marrer la consommation depuis Kafka
 */
async function startConsumingKafka() {
  try {
    // Connexion Redis
    await new Promise((resolve, reject) => {
      redisClient.on("connect", () => {
        console.log("‚úÖ Connect√© √† Redis");
        resolve();
      });
      redisClient.on("error", (err) => {
        console.error("‚ùå Erreur Redis:", err);
        reject(err);
      });
    });

    // Connexion Kafka
    await consumer.connect();
    await consumer.subscribe({
      topic: TOPIC_NAME,
      fromBeginning: false,
    });

    await consumer.run({
      eachMessage: async ({ topic, partition, message }) => {
        // Extraire le correlation ID depuis les headers
        const correlationId = message.headers?.correlationId
          ? message.headers.correlationId.toString()
          : "unknown";

        const eventType = message.headers?.eventType
          ? message.headers.eventType.toString()
          : "unknown";

        console.log(
          `\nüì® [${correlationId}] Message re√ßu du topic ${topic}, partition ${partition}, offset ${message.offset}`
        );
        console.log(`   Type d'√©v√©nement: ${eventType}`);

        if (eventType === "booking.confirmed") {
          try {
            const eventData = JSON.parse(message.value.toString());
            const { bookingId } = eventData;

            // V√©rification de l'idempotence
            const alreadyProcessed = await isMessageAlreadyProcessed(
              bookingId,
              correlationId
            );

            if (alreadyProcessed) {
              console.log(`‚è≠Ô∏è [${correlationId}] Message ignor√© (d√©j√† trait√©)`);
              return; // Ne pas traiter √† nouveau
            }

            // Traiter le message
            await processBookingEvent(eventData, correlationId);

            // Marquer comme trait√© (expire apr√®s 24h)
            await markMessageAsProcessed(bookingId, correlationId);
          } catch (error) {
            console.error(
              `‚ùå [${correlationId}] Erreur lors du traitement:`,
              error
            );
            // Dans un vrai syst√®me, envoyer √† une dead letter queue
            throw error;
          }
        } else {
          console.log(
            `‚ö†Ô∏è [${correlationId}] Type d'√©v√©nement inconnu: ${eventType}`
          );
        }
      },
    });

    console.log(`\n‚úÖ Kafka Consumer d√©marr√©`);
    console.log(`   Topic: ${TOPIC_NAME}`);
    console.log(`   Group: ${GROUP_ID}`);
    console.log(`   Idempotence: Activ√©e (Redis)\n`);
  } catch (error) {
    console.error("‚ùå √âchec du d√©marrage du consumer Kafka:", error);
    process.exit(1);
  }
}

/**
 * D√©connexion gracieuse
 */
async function disconnectKafkaConsumer() {
  try {
    await consumer.disconnect();
    redisClient.quit();
    console.log("Kafka Consumer et Redis d√©connect√©s");
  } catch (error) {
    console.error("Erreur lors de la d√©connexion:", error);
  }
}

// Gestion de l'arr√™t gracieux
process.on("SIGTERM", disconnectKafkaConsumer);
process.on("SIGINT", disconnectKafkaConsumer);

// D√©marrer la consommation au d√©marrage du service
startConsumingKafka();
```

#### Partie 3 : Configuration Docker Compose avec Redis

```yaml
# docker-compose.yml
version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3

  redis:
    image: redis:7-alpine
    hostname: redis
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data

volumes:
  redis-data:
```

#### Partie 4 : Installation des D√©pendances

```bash
# Dans booking-service
npm install kafkajs uuid

# Dans notification-service
npm install kafkajs redis
```

#### R√©sultat Attendu

**Premier message** :

```
üì§ [a1b2c3d4-e5f6-7890] Tentative d'envoi du message vers Kafka...
‚úÖ [a1b2c3d4-e5f6-7890] Message publi√© vers Kafka avec succ√®s

üì® [a1b2c3d4-e5f6-7890] Message re√ßu du topic tour_booking_events, partition 0, offset 42
   Type d'√©v√©nement: booking.confirmed

üìß [a1b2c3d4-e5f6-7890] Traitement de la notification...
   R√©servation: bkg_123
   Utilisateur: user_001
   Tour: Paris City Tour
   Montant: 199.99 USD
‚úÖ [a1b2c3d4-e5f6-7890] Notification envoy√©e avec succ√®s!
‚úÖ [a1b2c3d4-e5f6-7890] Message marqu√© comme trait√©: bkg_123 (expire dans 86400s)
```

**Message dupliqu√©** :

```
üì® [a1b2c3d4-e5f6-7890] Message re√ßu du topic tour_booking_events, partition 0, offset 43
   Type d'√©v√©nement: booking.confirmed
‚ö†Ô∏è [a1b2c3d4-e5f6-7890] Message d√©j√† trait√©: bkg_123
‚è≠Ô∏è [a1b2c3d4-e5f6-7890] Message ignor√© (d√©j√† trait√©)
```

**√âchec avec retry** :

```
üì§ [x9y8z7w6-v5u4-3210] Tentative d'envoi du message vers Kafka...
‚ö†Ô∏è [x9y8z7w6-v5u4-3210] Tentative 1/5 √©chou√©e. Nouvelle tentative dans 200ms...
‚ö†Ô∏è [x9y8z7w6-v5u4-3210] Tentative 2/5 √©chou√©e. Nouvelle tentative dans 400ms...
‚úÖ [x9y8z7w6-v5u4-3210] Message publi√© vers Kafka avec succ√®s
```

---

## Exercice 3 : Choisir une Message Queue

### √ânonc√©

**Objectif** : Analyser et justifier le choix entre RabbitMQ et Kafka pour diff√©rents sc√©narios.

**T√¢ches** :

R√©digez une analyse (2-3 paragraphes) pour chacun des sc√©narios suivants, en justifiant votre choix de RabbitMQ ou Kafka :

1. **Sc√©nario A** : Envoi d'emails de confirmation de r√©servation (latence max 5 secondes, volume: 1000 msg/jour)
2. **Sc√©nario B** : Collecte et analyse en temps r√©el de tous les clics utilisateurs sur l'application web (volume: 1M+ √©v√©nements/jour, besoin de rejouer les √©v√©nements pour analytics)
3. **Sc√©nario C** : Workflow de traitement de paiement avec compensation en cas d'√©chec (besoin de garanties fortes de livraison, dead letter queues)

---

### Solution

#### Sc√©nario A : Envoi d'Emails de Confirmation de R√©servation

**Choix recommand√© : RabbitMQ** ‚úÖ

**Justification** :

Pour l'envoi d'emails de confirmation de r√©servation, **RabbitMQ** est le choix optimal pour plusieurs raisons. Premi√®rement, le volume de 1000 messages par jour est relativement faible (environ 0,7 msg/sec en moyenne), ce qui est largement dans les capacit√©s de RabbitMQ sans n√©cessiter l'overhead de Kafka. La latence maximale de 5 secondes est facilement respect√©e avec RabbitMQ, qui offre une latence typique de quelques millisecondes √† quelques centaines de millisecondes.

Deuxi√®mement, les emails de confirmation sont des messages **√©ph√©m√®res** : une fois l'email envoy√©, il n'y a pas besoin de conserver l'√©v√©nement pour un traitement ult√©rieur. RabbitMQ permet de supprimer automatiquement les messages apr√®s leur consommation et acknowledgement, ce qui r√©duit l'utilisation du stockage. De plus, RabbitMQ offre des fonctionnalit√©s natives comme les **dead letter queues** (DLQ) qui sont essentielles pour g√©rer les √©checs d'envoi d'email (adresse invalide, serveur SMTP temporairement indisponible). Les messages qui √©chouent apr√®s plusieurs tentatives peuvent √™tre automatiquement rout√©s vers une DLQ pour investigation manuelle.

Enfin, la simplicit√© op√©rationnelle de RabbitMQ est un avantage majeur pour ce cas d'usage. L'√©quipe peut rapidement mettre en place un syst√®me fiable avec un minimum de configuration, et l'interface de gestion web de RabbitMQ facilite le monitoring des queues et le d√©pannage. Pour un syst√®me de notifications comme celui-ci, o√π la complexit√© de Kafka n'apporte pas de valeur ajout√©e significative, RabbitMQ repr√©sente le meilleur rapport simplicit√©/efficacit√©.

**Architecture recommand√©e** :

```
Booking Service
       ‚îÇ
       ‚îî‚îÄ‚îÄ> Exchange "notifications"
              ‚îÇ
              ‚îú‚îÄ‚îÄ> Queue "email_confirmations" ‚îÄ‚îÄ> Email Service
              ‚îÇ                                    (Retry 3x)
              ‚îÇ                                         ‚îÇ
              ‚îÇ                                         ‚îÇ (√©checs)
              ‚îÇ                                         v
              ‚îî‚îÄ‚îÄ> Dead Letter Queue "email_failed" ‚îÄ‚îÄ> Monitoring
```

---

#### Sc√©nario B : Collecte et Analyse en Temps R√©el des Clics Utilisateurs

**Choix recommand√© : Apache Kafka** ‚úÖ

**Justification** :

Pour la collecte et l'analyse de clics utilisateurs √† grande √©chelle, **Apache Kafka** est indiscutablement la meilleure solution. Le volume de 1M+ √©v√©nements par jour (environ 12-15 √©v√©nements/seconde en moyenne, avec des pics potentiellement beaucoup plus √©lev√©s) d√©passe largement le sweet spot de RabbitMQ et entre dans le domaine o√π Kafka excelle. Kafka est sp√©cifiquement con√ßu pour g√©rer des flux d'√©v√©nements √† tr√®s haut d√©bit, avec des capacit√©s de traitement pouvant atteindre des centaines de milliers voire millions de messages par seconde.

Le besoin de **rejouer les √©v√©nements** pour l'analytics est l'argument d√©cisif en faveur de Kafka. Contrairement √† RabbitMQ qui supprime les messages apr√®s consommation, Kafka conserve tous les √©v√©nements dans un log immuable pendant une p√©riode configurable (jours, semaines, voire ind√©finiment). Cette capacit√© de **replayability** est cruciale pour plusieurs cas d'usage : recalculer les m√©triques historiques apr√®s avoir corrig√© un bug dans le code d'analytics, former de nouveaux mod√®les de machine learning sur des donn√©es historiques, ou permettre √† de nouveaux consumers (par exemple, un nouveau dashboard analytics) de traiter l'historique complet des clics depuis le d√©but.

De plus, l'architecture distribu√©e de Kafka avec son syst√®me de **partitions** permet de parall√©liser facilement le traitement des clics. Par exemple, on peut partitionner les √©v√©nements par `userId` pour garantir que tous les clics d'un m√™me utilisateur sont trait√©s dans l'ordre par le m√™me consumer, tout en distribuant la charge de traitement sur plusieurs instances. Cette scalabilit√© horizontale native de Kafka est essentielle pour maintenir des performances constantes m√™me quand le volume d'√©v√©nements augmente. Le mod√®le de consumer groups de Kafka permet √©galement d'avoir plusieurs √©quipes (analytics, marketing, product) qui consomment ind√©pendamment le m√™me flux d'√©v√©nements, chacune avec son propre offset.

**Architecture recommand√©e** :

```
Web App / Mobile App
       ‚îÇ
       ‚îî‚îÄ‚îÄ> Kafka Topic "user_clicks" (12 partitions)
              ‚îÇ
              ‚îú‚îÄ‚îÄ> Consumer Group "realtime_analytics"
              ‚îÇ    ‚îî‚îÄ‚îÄ> 4 instances (analytics en temps r√©el)
              ‚îÇ
              ‚îú‚îÄ‚îÄ> Consumer Group "data_warehouse"
              ‚îÇ    ‚îî‚îÄ‚îÄ> 2 instances (sauvegarde en S3/BigQuery)
              ‚îÇ
              ‚îî‚îÄ‚îÄ> Consumer Group "ml_training"
                   ‚îî‚îÄ‚îÄ> 1 instance (entra√Ænement mod√®les ML)
```

---

#### Sc√©nario C : Workflow de Traitement de Paiement avec Compensation

**Choix recommand√© : RabbitMQ** ‚úÖ

**Justification** :

Pour un workflow de traitement de paiement avec m√©canisme de compensation, **RabbitMQ** offre les garanties et les fonctionnalit√©s les mieux adapt√©es. Le traitement des paiements n√©cessite des **garanties de livraison extr√™mement fortes** : aucun message de paiement ne peut √™tre perdu, et chaque paiement doit √™tre trait√© exactement une fois (ou au moins avec idempotence garantie). RabbitMQ, avec son protocole AMQP et son syst√®me d'acknowledgements manuels, offre une fiabilit√© √©prouv√©e pour ce type de workflows critiques. La capacit√© d'attendre l'acknowledgement explicite du consumer avant de supprimer le message de la queue garantit qu'aucune transaction n'est perdue m√™me en cas de crash d'un service.

Les **dead letter queues** (DLQ) de RabbitMQ sont essentielles pour impl√©menter un syst√®me de compensation robuste dans les workflows de paiement. Quand une √©tape du workflow √©choue (par exemple, le paiement est refus√© par la banque, ou le service d'inventory ne peut pas r√©server les places), le message peut √™tre automatiquement rout√© vers une DLQ sp√©cifique. Ce m√©canisme permet d'impl√©menter facilement le pattern Saga avec des transactions compensatoires : on peut avoir une queue "payment_compensation" qui d√©clenche l'annulation de la r√©servation et le remboursement du client. RabbitMQ permet √©galement de configurer des d√©lais de retry avec backoff exponentiel directement au niveau du broker, sans logique complexe dans le code applicatif.

Le **routage sophistiqu√©** de RabbitMQ via les exchanges (topic, direct, fanout) est particuli√®rement utile pour orchestrer les diff√©rentes √©tapes d'un workflow de paiement complexe. Par exemple, on peut utiliser des routing keys comme `payment.initiated`, `payment.authorized`, `payment.captured`, `payment.failed` pour router les messages vers les queues appropri√©es selon l'√©tat de la transaction. Cette flexibilit√© de routage, combin√©e avec la possibilit√© de d√©finir des **Time-To-Live (TTL)** et des **priority queues**, permet d'impl√©menter des workflows de paiement sophistiqu√©s avec timeouts et gestion des priorit√©s (par exemple, traiter en priorit√© les paiements premium).

**Architecture recommand√©e** :

```
API Gateway
       ‚îÇ
       ‚îî‚îÄ‚îÄ> Exchange "payments" (Topic)
              ‚îÇ
              ‚îú‚îÄ‚îÄ> [routing: payment.initiated]
              ‚îÇ    ‚îî‚îÄ‚îÄ> Queue "payment_processing" ‚îÄ‚îÄ> Payment Service
              ‚îÇ                                         (Retry 3x, TTL: 30s)
              ‚îÇ                                              ‚îÇ
              ‚îÇ                                              ‚îú‚îÄ [success]
              ‚îÇ                                              ‚îÇ  ‚îî‚îÄ‚îÄ> publish "payment.captured"
              ‚îÇ                                              ‚îÇ
              ‚îÇ                                              ‚îî‚îÄ [failure]
              ‚îÇ                                                 ‚îî‚îÄ‚îÄ> DLQ "payment_failed"
              ‚îÇ
              ‚îú‚îÄ‚îÄ> [routing: payment.captured]
              ‚îÇ    ‚îî‚îÄ‚îÄ> Queue "booking_confirmation" ‚îÄ‚îÄ> Booking Service
              ‚îÇ                                          (finalise r√©servation)
              ‚îÇ
              ‚îî‚îÄ‚îÄ> [routing: payment.failed]
                   ‚îî‚îÄ‚îÄ> Queue "payment_compensation" ‚îÄ‚îÄ> Compensation Service
                                                         (annulation + remboursement)
```

**Avantages sp√©cifiques pour les paiements** :

- ‚úÖ **Durabilit√©** : Messages persist√©s sur disque
- ‚úÖ **Acknowledgements manuels** : Pas de perte de messages
- ‚úÖ **Dead Letter Queues** : Gestion des √©checs et compensation
- ‚úÖ **TTL et Priority** : Timeouts et priorit√©s des transactions
- ‚úÖ **Routage flexible** : Orchestration des workflows complexes
- ‚úÖ **Monitoring simple** : Interface web pour surveiller l'√©tat des queues

---

## Conclusion

Ces trois exercices d√©montrent l'importance de comprendre les caract√©ristiques et les trade-offs entre RabbitMQ et Kafka pour choisir la solution appropri√©e selon le cas d'usage :

- **RabbitMQ** excelle pour les **task queues**, les **workflows transactionnels**, et les cas o√π les **garanties de livraison** et le **routage complexe** sont critiques.

- **Kafka** est optimal pour les **flux d'√©v√©nements √† haut d√©bit**, les **analytics en temps r√©el**, et les cas n√©cessitant la **replayability** et le **traitement distribu√©**.

Le choix ne doit pas √™tre dogmatique : de nombreuses architectures modernes utilisent **les deux** en fonction des besoins sp√©cifiques de chaque composant du syst√®me.
