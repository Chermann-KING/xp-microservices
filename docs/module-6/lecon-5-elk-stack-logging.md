# Le√ßon 6.5 ‚Äì Logging et Monitoring Centralis√©s avec la Stack ELK (Elasticsearch, Logstash, Kibana)

---

## Objectifs p√©dagogiques

- Comprendre le r√¥le de la Stack ELK pour la supervision des microservices
- Savoir configurer la collecte, le traitement et la visualisation des logs
- Mettre en place un pipeline de logs structur√© pour l‚Äôapplication de tourisme
- Cr√©er des dashboards de monitoring dans Kibana

---

## Introduction

Les architectures microservices, comme notre application de r√©servation touristique, g√©n√®rent de grandes quantit√©s de logs et de m√©triques r√©partis sur de nombreux services. Le logging et le monitoring centralis√©s deviennent essentiels pour comprendre le comportement du syst√®me, diagnostiquer les probl√®mes et garantir la sant√© op√©rationnelle. La Stack **ELK** (Elasticsearch, Logstash, Kibana) offre une solution open source puissante pour agr√©ger, traiter, stocker et visualiser ces donn√©es distribu√©es.

---

## 1. Pr√©sentation de la Stack ELK

La Stack ELK regroupe trois produits open source d‚ÄôElastic, con√ßus pour fonctionner ensemble et fournir une solution robuste de gestion et d‚Äôanalyse des logs¬†:

- **Elasticsearch**¬†: moteur de recherche et d‚Äôanalytique distribu√©, stockage centralis√© des logs
- **Logstash**¬†: pipeline de collecte, transformation et enrichissement des logs
- **Kibana**¬†: interface web de visualisation, d‚Äôexploration et de dashboarding

### 1.1 Elasticsearch : Moteur de Recherche et d‚ÄôAnalytique

- Stocke les logs sous forme de documents JSON, sans sch√©ma strict
- Permet la recherche temps r√©el, l‚Äôagr√©gation et l‚Äôanalyse rapide de gros volumes de donn√©es
- Distribu√© et scalable¬†: les donn√©es sont r√©parties sur plusieurs n≈ìuds (sharding/r√©plication)
- API RESTful pour l‚Äôindexation, la recherche et la r√©cup√©ration des donn√©es
- Les logs de chaque microservice (ex¬†: Tour Catalog, Booking Management) sont index√©s dans des indices d√©di√©s ou par date (ex¬†: `booking-tourism-app-logs-2026.01.11`)

### 1.2 Logstash : Pipeline de Collecte et de Traitement

- Ingestion de donn√©es depuis de multiples sources (fichiers, Filebeat, TCP, Kafka, RabbitMQ‚Ä¶)
- Filtres puissants pour parser, transformer et enrichir les logs (grok, mutate, date, json, geoip‚Ä¶)
- Envoie les donn√©es trait√©es vers Elasticsearch (ou d‚Äôautres destinations)
- Architecture √† plugins (inputs, filters, outputs)

**Exemple de configuration Logstash pour logs d‚Äôun microservice¬†:**

```conf
input {
  file {
    path => "/var/log/tour-catalog/app.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}
filter {
  grok {
    match => { "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] %{LOGLEVEL:log_level} %{WORD:service_name} - Request %{WORD:http_method} %{URIPATH:request_path} from user: %{WORD:user_id} completed with status %{NUMBER:http_status}" }
  }
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  mutate {
    add_field => { "application" => "TourismApp" }
    add_field => { "service" => "TourCatalog" }
    convert => { "http_status" => "integer" }
  }
}
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "booking-tourism-app-logs-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}
```

### 1.3 Kibana : Visualisation et Dashboarding

- Interface web pour explorer, filtrer et visualiser les logs
- Cr√©ation de dashboards personnalis√©s (graphiques, tableaux, cartes‚Ä¶)
- Outils de recherche avanc√©e (KQL, Lucene)
- Monitoring de la sant√© des services, analyse des erreurs, suivi des performances

---

## 2. Mettre en place le Logging Centralis√© pour l‚ÄôApp de Tourisme

### 2.1 Strat√©gie de collecte des logs

- Utiliser **Filebeat** (ou un √©quivalent) sur chaque h√¥te ou conteneur microservice pour exp√©dier les logs vers Logstash
- Les microservices doivent produire des logs structur√©s (JSON recommand√©) pour faciliter le parsing

**Exemple avec Winston (Node.js)¬†:**

```js
// tour-catalog-service/src/logger.js
const winston = require("winston");
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || "info",
  format: winston.format.json(),
  transports: [new winston.transports.Console()],
  defaultMeta: { service: "tour-catalog-service" },
});
module.exports = logger;
```

### 2.2 D√©ploiement de la Stack ELK avec Docker Compose

**Exemple de fichier¬†docker-compose.elk.yml¬†:**

```yaml
version: "3.8"
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - elk-network
  logstash:
    image: docker.elastic.co/logstash/logstash:8.9.0
    build:
      context: ./logstash
      dockerfile: Dockerfile
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./tour-catalog-service/logs:/var/log/tour-catalog:ro
    ports:
      - 5044:5044
    environment:
      - LS_JAVA_OPTS=-Xms256m -Xmx256m
    depends_on:
      - elasticsearch
    networks:
      - elk-network
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    ports:
      - 5601:5601
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - elk-network
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.9.0
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5044
    depends_on:
      - logstash
    networks:
      - elk-network
volumes:
  esdata:
networks:
  elk-network:
    driver: bridge
```

---

## 3. Monitoring et Visualisation dans Kibana

### 3.1 D√©couverte et recherche de logs

- Cr√©er un index pattern (ex¬†: `booking-tourism-app-logs-*`)
- Utiliser l‚Äôonglet "Discover" pour explorer les logs bruts, filtrer par service, niveau, utilisateur, etc.
- Exemple¬†: `service_name: "BookingManagement" AND log_level: "ERROR"`

### 3.2 Cr√©ation de dashboards

- Histogramme de la distribution des temps de r√©ponse
- M√©trique du nombre d‚Äôerreurs sur 15 minutes
- Tableau des messages d‚Äôerreur les plus fr√©quents
- Bar chart du volume de logs par service et par niveau
- Dashboard "Tourism App Health Monitor" combinant plusieurs visualisations

---

## 4. Exercices pratiques

### Exercice 1¬†: Configurer le logging structur√©

- Modifiez le fichier `logger.js` d‚Äôun microservice Node.js pour produire des logs JSON avec Winston ou Pino.
- Assurez-vous d‚Äôinclure¬†: timestamp, level, service_name, message, et des champs contextuels (ex¬†: tourId, userId).

### Exercice 2¬†: Cr√©er un pipeline Logstash personnalis√©

- Ajoutez un microservice (ex¬†: notification-service) √† votre `docker-compose.elk.yml`.
- Cr√©ez une configuration Filebeat pour ce service.
- √âcrivez une configuration Logstash d√©di√©e (ex¬†: `notification-service.conf`) pour parser ses logs et extraire le champ user_id.
- V√©rifiez dans Kibana que les logs apparaissent correctement.

### Exercice 3¬†: Construire un dashboard Kibana

- Cr√©ez un dashboard "Tourism App Health Monitor" dans Kibana.
- Ajoutez¬†:
  - Une m√©trique du nombre total d‚Äôerreurs
  - Un bar chart du breakdown log_level/service_name
  - Un tableau des messages d‚Äôerreur les plus fr√©quents
  - Un graphe du volume de logs par service dans le temps
- Exportez ou partagez la configuration du dashboard.

---

## 5. Prochaines √©tapes

Le logging centralis√© avec la Stack ELK offre une visibilit√© essentielle sur vos microservices. Les prochaines le√ßons aborderont les techniques avanc√©es de scaling, la mont√©e en charge de la stack ELK elle-m√™me, et l‚Äôutilisation des logs pour le debugging et la validation du comportement syst√®me.

---

## Navigation

- **‚¨ÖÔ∏è Pr√©c√©dent** : [Le√ßon 6.4 ‚Äì Impl√©mentation d‚Äôun API Gateway](lecon-4-api-gateway-implementation.md)
- **‚û°Ô∏è Suivant** : [Le√ßon 6.6 ‚Äì Scaling avanc√© des microservices](lecon-6-scaling-advanced.md)
- **üè† Sommaire** : [Retour au README](README.md)

---
